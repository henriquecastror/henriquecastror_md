@article{Abadie2010,
abstract = {Building on an idea in Abadie and Gardeazabal (2003), this article investigates the application of synthetic control methods to comparative case studies. We discuss the advantages of these methods and apply them to study the effects of Proposition 99, a large-scale tobacco control program that California implemented in 1988. We demonstrate that, following Proposition 99, tobacco consumption fell markedly in California relative to a comparable synthetic control region. We estimate that by the year 2000 annual per-capita cigarette sales in California were about 26 packs lower than what they would have been in the absence of Proposition 99. Using new inferential methods proposed in this article, we demonstrate the significance of our estimates. Given that many policy interventions and events of interest in social sciences take place at an aggregate level (countries, regions, cities, etc.) and affect a small number of aggregate units, the potential applicability of synthetic control methods to comparative case studies is very large, especially in situations where traditional regression methods are not appropriate. {\textcopyright} 2010 American Statistical Association.},
author = {Abadie, Alberto and Diamond, Alexis and Hainmueller, And Jens},
doi = {10.1198/jasa.2009.ap08746},
file = {:D$\backslash$:/Dropbox/Artigos/Mendeley/Abadie, Diamond, Hainmueller - 2010 - Synthetic control methods for comparative case studies Estimating the effect of California's Tobac.pdf:pdf},
issn = {01621459},
journal = {Journal of the American Statistical Association},
keywords = {Observational studies,Proposition 99,Tobacco control legislation,Treatment effects},
mendeley-groups = {1 CF{\&}G 4 Econometrics},
number = {490},
pages = {493--505},
title = {{Synthetic control methods for comparative case studies: Estimating the effect of California's Tobacco control program}},
volume = {105},
year = {2010}
}



@article{AtanasovBlack2016,
abstract = {We study shock-based methods for credible causal inference in corporate finance research. We focus on corporate governance research, survey 13,461 papers published between 2001 and 2011 in 22 major accounting, economics, finance, law, and management journals; and identify 863 empirical studies in which corporate governance is associated with firm value or other characteristics. We classify the methods used in these studies and assess whether they support a causal link between corporate governance and firm value or another outcome. Only a stall minority of studies have convincing causal inference strategies. The convincing strategies largely rely on external shocks – usually from legal rules – often called “natural experiments”. We examine the 74 shock-based papers and provide a guide to shock-based research design, which stresses the common features across different designs and the value of using combined designs. },
author = {Atanasov, Vladimir and Black, Bernard},
doi = {10.1561/104.00000036},
file = {:D$\backslash$:/Dropbox/Artigos/Mendeley/Atanasov, Black - 2016 - Shock-Based Causal Inference in Corporate Finance and Accounting Research - Critical Finance Review(2).pdf:pdf},
issn = {21645744},
journal = {Critical Finance Review},
keywords = {c18,causal inference,corporate governance,difference-in-differences,g34,g38,identification,instrumental variables,jel codes,m48,nat-,placebo tests,regression discontinuity,shock-based inference,ural experiments},
mendeley-groups = {1 CF{\&}G 4 Econometrics},
number = {2},
pages = {207--304},
title = {{Shock-Based Causal Inference in Corporate Finance and Accounting Research}},
volume = {5},
year = {2016}
}

@article{Bascle2008,
abstract = {This article offers a framework to understand how endogeneity arises and how to control for it with instrumental variables to estimate causal relations with observational data. It builds on the state-of-the-art research in applied and theoretical econometrics to highlight the importance of endogeneity and review the methods that can be used to address it with instrumental variables. The article also discusses when the Heckman two-step procedure can be used, as well as the tests, methods and assumptions that researchers should check when using instrumental variables. To ease implementation of the instrumental variables techniques, the author offers the STATA commands of the exposed tests and methods. Further, an empirical example is provided along with the utilized STATA codes. In the end, this article serves as a 'toolkit' allowing scholars not only to understand whether endogeneity is present in their empirical setting, but also to assess the empirical validity of their work when using instrumental variables. {\textcopyright} 2008 Sage Publications.},
author = {Bascle, Guilhem},
doi = {10.1177/1476127008094339},
file = {:D$\backslash$:/Dropbox/Artigos/Mendeley/Bascle - 2008 - Controlling for endogeneity with instrumental variables in strategic management research - Strategic Organization.pdf:pdf},
issn = {14761270},
journal = {Strategic Organization},
keywords = {Causal relations,Endogeneity,Instrumental variables},
mendeley-groups = {1 CF{\&}G 4 Econometrics},
number = {3},
pages = {285--327},
title = {{Controlling for endogeneity with instrumental variables in strategic management research}},
volume = {6},
year = {2008}
}

@article{Bertrand2004,
author = {Bertrand, M. and Duflo, E. and Mullainathan, S.},
doi = {10.1162/003355304772839588},
file = {:D$\backslash$:/Dropbox/Artigos/Mendeley/Bertrand, Duflo, Mullainathan - 2004 - How Much Should We Trust Differences-In-Differences Estimates - The Quarterly Journal of Economic.pdf:pdf},
issn = {0033-5533},
journal = {The Quarterly Journal of Economics},
mendeley-groups = {1 CF{\&}G 4 Econometrics},
month = {feb},
number = {1},
pages = {249--275},
title = {{How Much Should We Trust Differences-In-Differences Estimates?}},
url = {https://academic.oup.com/qje/article-lookup/doi/10.1162/003355304772839588},
volume = {119},
year = {2004}
}


@article{Bowen2017,
abstract = {We study the diffusion of techniques designed to identify causal relationships in corporate finance research. We estimate that the diffusion started in the mid-1990s, lagged 20 years compared to economics, and is now used in the majority of corporate finance articles. Consistent with recent theories of technology diffusion, the adoption varies across researchers based on individuals' expected net benefits of adoption. Younger scholars, holders of PhDs in economics, and those working at top institutions adopt faster. Adoption is accelerated through networks of colleagues and alumni and is also facilitated by straddlers who cross over from economics to finance. Our findings highlight newforces that explain the diffusion of innovation and shape the norms of academic research.},
author = {Bowen, Donald E. and Fr{\'{e}}sard, Laurent and Taillard, J{\'{e}}r{\^{o}}me P.},
doi = {10.1287/mnsc.2016.2437},
file = {:D$\backslash$:/Dropbox/Artigos/Mendeley/Bowen, Fr{\'{e}}sard, Taillard - 2017 - What's your identification strategy Innovation in corporate finance research - Management Science.pdf:pdf},
issn = {15265501},
journal = {Management Science},
keywords = {Causality,Corporate finance,Identification,Technology diffusion},
mendeley-groups = {1 CF{\&}G 4 Econometrics},
number = {8},
pages = {2529--2548},
title = {{What's your identification strategy? Innovation in corporate finance research}},
volume = {63},
year = {2017}
}

@book{CappelleriTrochim2015,
abstract = {The regression-discontinuity (RD) research design assigns participants to treatment groups solely on the basis of a pretreatment cutoff score, allowing the relative effect of treatment to be studied in participants who most need or deserve a particular treatment. In this article a brief history of the design is given, the basic RD design structure is described, design considerations and variations are highlighted (on cutoff selection, assignment variations, multiple cutoff points, multiple assignment measures, treatment variations, and posttreatment measurement variations, internal validity, measurement error, statistical power), and recent methodological developments are presented (on nonparametric statistical analysis, the 'fuzzy' RD design, and design variations).},
author = {Cappelleri, Joseph C. and Trochim, William M.},
booktitle = {International Encyclopedia of the Social {\&} Behavioral Sciences: Second Edition},
doi = {10.1016/B978-0-08-097086-8.44049-3},
edition = {Second Edi},
file = {:D$\backslash$:/Dropbox/Artigos/Mendeley/Cappelleri, Trochim - 2015 - Regression Discontinuity Design - International Encyclopedia of the Social {\&} Behavioral Sciences Second Edi.pdf:pdf},
isbn = {9780080970875},
keywords = {Assignment variations,Cutoff selection,Design variations,Fuzzy regression-discontinuity design,Instrumental variables,Internal validity,Measurement error,Multiple assignment measures,Multiple cutoff points,Nonparametric analysis,Parametric analysis,Quasi-experimental design,Regression analysis,Regression-discontinuity design,Statistical power},
mendeley-groups = {1 CF{\&}G 4 Econometrics},
number = {2008},
pages = {152--159},
publisher = {Elsevier},
title = {{Regression Discontinuity Design}},
volume = {19},
year = {2015}
}


@article{Gormley2014,
abstract = {Controlling for unobserved heterogeneity (or "common errors"), such as industry-specific shocks, is a fundamental challenge in empirical research. This paper discusses the limitations of two approaches widely used in corporate finance and asset pricing research: demeaning the dependent variable with respect to the group (e.g., "industry-adjusting") and adding the mean of the group's dependent variable as a control. We show that these methods produce inconsistent estimates and can distort inference. In contrast, the fixed effects estimator is consistent and should be used instead. We also explain how to estimate the fixed effects model when traditional methods are computationally infeasible. {\textcopyright} 2013 The Author 2013. Published by Oxford University Press on behalf of The Society for Financial Studies. All rights reserved.},
author = {Gormley, Todd A. and Matsa, David A.},
doi = {10.1093/rfs/hht047},
file = {:D$\backslash$:/Dropbox/Artigos/Mendeley/Gormley, Matsa - 2014 - Common errors How to (and Not to) control for unobserved heterogeneity - Review of Financial Studies.pdf:pdf},
issn = {08939454},
journal = {Review of Financial Studies},
mendeley-groups = {1 CF{\&}G 4 Econometrics},
month = {feb},
number = {2},
pages = {617--661},
title = {{Common errors: How to (and Not to) control for unobserved heterogeneity}},
volume = {27},
year = {2014}
}

@article{Gow2016,
abstract = {This paper examines the approaches accounting researchers adopt to draw causal inferences using observational (or nonexperimental) data. The vast majority of accounting research papers draw causal inferences notwithstanding the well-known difficulties in doing so. While some recent papers seek to use quasi-experimental methods to improve causal inferences, these methods also make strong assumptions that are not always fully appreciated. We believe that accounting research would benefit from more in-depth descriptive research, including a greater focus on the study of causal mechanisms (or causal pathways) and increased emphasis on the structural modeling of the phenomena of interest. We argue these changes offer a practical path forward for rigorous accounting research.},
author = {Gow, Ian D. and Larcker, David F. and Reiss, Peter C.},
doi = {10.1111/1475-679X.12116},
file = {:D$\backslash$:/Dropbox/Artigos/Mendeley/Gow, Larcker, Reiss - 2016 - Causal Inference in Accounting Research - Journal of Accounting Research.pdf:pdf},
issn = {1475679X},
journal = {Journal of Accounting Research},
keywords = {Accounting research,Causal inference,Quasi-experimental methods,Structural modeling},
mendeley-groups = {1 CF{\&}G 4 Econometrics},
number = {2},
pages = {477--523},
title = {{Causal Inference in Accounting Research}},
volume = {54},
year = {2016}
}
@article{Lindner2019,
abstract = {Collinearity between independent variables is a recurrent problem in quantitative empirical research in International Business (IB). We explore insufficient and inappropriate treatment of collinearity and use simulations to illustrate the potential impact on results. We also show how IB researchers doing quantitative work can avoid collinearity issues that lead to spurious and unstable results. Our six principal insights are the following: first, multicollinearity does not introduce bias. It is not an econometric problem in the sense that it would violate assumptions necessary for regression models to work. Second, variance inflation factors are indicators of standard errors that are too large, not too small. Third, coefficient instability is not a consequence of multicollinearity. Fourth, in the presence of a higher partial correlation between the variables, it can paradoxically become more problematic to omit one of these variables. Fifth, ignoring clusters in data can lead to spurious results. Sixth, accounting for country clusters does not pick up all country-level variation.},
author = {Lindner, Thomas and Puck, Jonas and Verbeke, Alain},
doi = {10.1057/s41267-019-00257-1},
file = {:D$\backslash$:/Dropbox/Artigos/Mendeley/Lindner, Puck, Verbeke - 2019 - Misconceptions about multicollinearity in international business research Identification, consequences,.pdf:pdf},
issn = {0047-2506},
journal = {Journal of International Business Studies},
keywords = {collinearity,hierarchical modeling,multicollinearity,quantitative research methods,regression analysis},
mendeley-groups = {1 CF{\&}G 4 Econometrics},
month = {aug},
publisher = {Palgrave Macmillan UK},
title = {{Misconceptions about multicollinearity in international business research: Identification, consequences, and remedies}},
url = {http://link.springer.com/10.1057/s41267-019-00257-1},
year = {2019}
}



@article{KahnWhited2018,
abstract = {We distinguish between identification and establishing causality. Identification means forming a unique mapping from features of data to quantities that are of interest to economists. Establishing causality by finding sources of exogenous variation is often considered synonymous with identification, but these two concepts are distinct. Exogenous variation is only sometimes necessary and never sufficient to identify economically interesting parameters. Instead, even for causal questions, identification must rest on an underlying economic model. We illustrate these points by analyzing identification in three recent papers and by examining the estimation of a simple dynamic model.},
author = {Kahn, R. and Whited, Toni M.},
doi = {10.1093/rcfs/cfx020},
file = {:D$\backslash$:/Dropbox/Artigos/Mendeley/Kahn, Whited - 2018 - Identification is not causality, and vice versa - Review of Corporate Finance Studies.pdf:pdf},
issn = {20469136},
journal = {Review of Corporate Finance Studies},
mendeley-groups = {1 CF{\&}G 4 Econometrics},
number = {1},
pages = {1--21},
title = {{Identification is not causality, and vice versa}},
volume = {7},
year = {2018}
}

@article{Jiang2017,
abstract = {A survey of 255 papers that rely on the instrumental variable (IV) approach for identifying causal effects published in the “Big Three” finance journals reveals that IV estimates are larger than their corresponding uninstrumented estimates in about 80{\%} of the studies, regardless of whether the potential endogeneity is expected to create a positive or negative bias based on economic reasoning. The magnitude of the IV estimates is, on average, nine times of that of the uninstrumented estimates even when economic insights do not suggest a downward bias of the latter. This study provides several explanations to the “implausibly large” IV estimates in finance research, and proposes best practices for identification-conscientious researchers.},
author = {Jiang, Wei},
doi = {10.1093/rcfs/cfx015},
file = {:D$\backslash$:/Dropbox/Artigos/Mendeley/Jiang - 2017 - Have instrumental variables brought US closer to the truth - Review of Corporate Finance Studies.pdf:pdf},
issn = {20469136},
journal = {Review of Corporate Finance Studies},
mendeley-groups = {1 CF{\&}G 4 Econometrics},
number = {2},
pages = {127--140},
title = {{Have instrumental variables brought US closer to the truth}},
volume = {6},
year = {2017}
}


@article{Murray2006,
author = {Murray, Michael P},
file = {:D$\backslash$:/Dropbox/Artigos/Mendeley/Murray - 2006 - Avoiding Invalid Instruments and Coping with Weak Instruments - Journal of Economic Perspectives.pdf:pdf},
journal = {Journal of Economic Perspectives},
mendeley-groups = {1 CF{\&}G 4 Econometrics},
number = {4},
pages = {111--132},
title = {{Avoiding Invalid Instruments and Coping with Weak Instruments}},
volume = {20},
year = {2006}
}


@article{Petersen2009,
abstract = {In corporate finance and asset pricing empirical work, researchers are often confronted with panel data. In these data sets, the residuals may be correlated across firms or across time, and OLS standard errors can be biased. Historically, researchers in the two literatures have used different solutions to this problem. This paper examines the different methods used in the literature and explains when the different methods yield the same (and correct) standard errors and when they diverge. The intent is to provide intuition as to why the different approaches sometimes give different answers and give researchers guidance for their use. {\textcopyright} The Author 2008.},
author = {Petersen, Mitchell A.},
doi = {10.1093/rfs/hhn053},
file = {:D$\backslash$:/Dropbox/Artigos/Mendeley/Petersen - 2009 - Estimating standard errors in finance panel data sets Comparing approaches - Review of Financial Studies.pdf:pdf},
issn = {08939454},
journal = {Review of Financial Studies},
mendeley-groups = {1 CF{\&}G 4 Econometrics},
number = {1},
pages = {435--480},
title = {{Estimating standard errors in finance panel data sets: Comparing approaches}},
volume = {22},
year = {2009}
}

@article{Reeb2012,
abstract = {This essay builds on the exposition by Thomas et al. and focuses on analyzing cause and effect in international business research. We attempt to explain how endogeneity problems occur and why they are so prevalent in international business research in a non-technical fashion. We then discuss the importance of explicitly identifying how the chosen research design best approximates a randomized-controlled experiment. Finally, we provide some guidelines on achieving this goal and emphasize the practices that seem most relevant to JIBS reviewers in evaluating high-quality international business research. {\textcopyright} 2012 Academy of International Business All rights reserved.},
author = {Reeb, David and Sakakibara, Mariko and Mahmood, Ishtiaq P.},
doi = {10.1057/jibs.2011.60},
file = {:D$\backslash$:/Dropbox/Artigos/Mendeley/Reeb, Sakakibara, Mahmood - 2012 - From the editors Endogeneity in international business research - Journal of International Business S.pdf:pdf},
issn = {00472506},
journal = {Journal of International Business Studies},
keywords = {endogeneity,international business research,research design},
mendeley-groups = {1 CF{\&}G 4 Econometrics},
number = {3},
pages = {211--218},
publisher = {Nature Publishing Group},
title = {{From the editors: Endogeneity in international business research}},
volume = {43},
year = {2012}
}

@article{Roodman2009,
abstract = {The difference and system generalized method of moments (GMM) estimators are growing in popularity. As implemented in popular software, the estimators easily generate instruments that are numerous and, in system GMM, potentially suspect. A large instrument collection overfits endogenous variables even as it weakens the Hansen test of the instruments' joint validity. This paper reviews the evidence on the effects of instrument proliferation, and describes and simulates simple ways to control it. It illustrates the dangers by replicating Forbes [American Economic Review (2000) Vol. 90, pp. 869-887] on income inequality and Levine et al. [Journal of Monetary Economics] (2000) Vol. 46, pp. 31-77] on financial sector development. Results in both papers appear driven by previously undetected endogeneity. {\textcopyright} Center for Global Development 2009.},
author = {Roodman, David},
doi = {10.1111/j.1468-0084.2008.00542.x},
file = {:D$\backslash$:/Dropbox/Artigos/Mendeley/Roodman - 2009 - Practitioners' corner A note on the theme of too many instruments - Oxford Bulletin of Economics and Statistics.pdf:pdf},
issn = {03059049},
journal = {Oxford Bulletin of Economics and Statistics},
mendeley-groups = {1 CF{\&}G 4 Econometrics},
number = {1},
pages = {135--158},
title = {{Practitioners' corner: A note on the theme of too many instruments}},
volume = {71},
year = {2009}
}


@article{Roodman2009xtabond2,
author = {Roodman, David},
file = {:D$\backslash$:/Dropbox/Artigos/Mendeley/Roodman - 2009 - How to do xtabond2 An introduction to difference and system GMM in Stata - Stata Journal.pdf:pdf},
isbn = {9796964600},
journal = {Stata Journal},
mendeley-groups = {1 CF{\&}G 4 Econometrics},
number = {1},
pages = {86--136},
title = {{How to do xtabond2: An introduction to difference and system GMM in Stata}},
volume = {9},
year = {2009}
}

@book{RobertsWhited2013,
abstract = {This chapter discusses how applied researchers in corporate finance can address endogeneity concerns. We begin by reviewing the sources of endogeneity-omitted variables, simultaneity, and measurement error-and their implications for inference. We then discuss in detail a number of econometric techniques aimed at addressing endogeneity problems, including instrumental variables, difference-in-differences estimators, regression discontinuity design, matching methods, panel data methods, and higher order moments estimators. The unifying themes of our discussion are the emphasis on intuition and the applications to corporate finance. {\textcopyright} 2013 Elsevier B.V.},
author = {Roberts, Michael R. and Whited, Toni M.},
booktitle = {Handbook of the Economics of Finance},
doi = {10.1016/B978-0-44-453594-8.00007-0},
file = {:D$\backslash$:/Dropbox/Artigos/Mendeley/Roberts, Whited - 2013 - Endogeneity in Empirical Corporate Finance 1 - Unknown.pdf:pdf},
isbn = {9780444535948},
issn = {15740102},
keywords = {Difference-in-differences estimators,Instrumental variables,Matching estimators,Measurement error,Regression discontinuity designs},
mendeley-groups = {1 CF{\&}G 4 Econometrics},
number = {PA},
pages = {493--572},
title = {{Endogeneity in Empirical Corporate Finance}},
volume = {2},
year = {2013}
}

@article{Schiozer2020,
author = {Schiozer, Rafael F and Mourad, Frederico Abou and Martins, Theo Cotrim},
file = {:D$\backslash$:/Dropbox/Artigos/Mendeley/Schiozer, Mourad, Martins - 2020 - A tutorial on the use of Differences-in-Differences in Management, Finance, and Accounting - Journal.pdf:pdf},
journal = {Journal of Contemporary Administration},
keywords = {cash flow,lattice model,project volatility,real options,tutorial},
mendeley-groups = {1 CF{\&}G 4 Econometrics},
number = {1},
pages = {181--196},
title = {{A tutorial on the use of Differences-in-Differences in Management, Finance, and Accounting}},
volume = {25},
year = {2020}
}


@article{Stuart2010,
abstract = {Matching methods aim to improve the validity of causal inference in observational studies by reducing model dependence and offering intuitive diagnostics. While they have become a part of standard tool kit for empirical researchers across disciplines, matching methods are rarely used when analyzing time-series cross-section (TSCS) data, which consist of a relatively large number of repeated measurements on the same units. We develop a methodological framework that enables the application of matching methods to TSCS data. In the proposed approach, we first match each treated observation with control observations from other units in the same time period that have an identical treatment history up to the pre-specified number of lags. We use standard matching and weighting methods to further refine this matched set so that the treated observation has outcome and covariate histories similar to those of its matched control observations. Assessing the quality of matches is done by examining covariate balance. After the refinement, we estimate both short-term and long-term average treatment effects using the difference-indifferences estimator, accounting for a time trend. We also show that the proposed matching estimator can be written as a weighted linear regression estimator with unit and time fixed effects, providing model-based standard errors. We illustrate the proposed methodology by estimating the causal effects of democracy on economic growth, as well as the impact of interstate war on inheritance tax. The open-source software is available for implementing the proposed matching methods. The methods described in this paper can be implemented via the open-source statistical software, Panel-Match: Matching Methods for Causal Inference with Time-Series Cross-Section Data, available at https://github. com/insongkim/PanelMatch. We thank Matt Blackwell, Paul Kellstedt, Anton Strezhnev, and Yiqing Xu for comments and feedback.},
author = {Stuart, Elizabeth A.},
doi = {10.1214/09-STS313},
file = {:D$\backslash$:/Dropbox/Artigos/Mendeley/Stuart - 2010 - Matching Methods for Causal Inference A Review and a Look Forward - Statistical Science.pdf:pdf},
issn = {0883-4237},
journal = {Statistical Science},
keywords = {observational study,propensity scores,subclassification,weighting},
mendeley-groups = {1 CF{\&}G 4 Econometrics},
month = {feb},
number = {1},
pages = {1--21},
title = {{Matching Methods for Causal Inference: A Review and a Look Forward}},
volume = {25},
year = {2010}
}
@article{Wasserstein2016,
author = {Wasserstein, Ronald L. and Lazar, Nicole A.},
doi = {10.1080/00031305.2016.1154108},
file = {:D$\backslash$:/Dropbox/Artigos/Mendeley/Wasserstein, Lazar - 2016 - The ASA's Statement on p-Values Context, Process, and Purpose - American Statistician.pdf:pdf},
issn = {15372731},
journal = {American Statistician},
mendeley-groups = {1 CF{\&}G 4 Econometrics},
number = {2},
pages = {129--133},
publisher = {Taylor {\&} Francis},
title = {{The ASA's Statement on p-Values: Context, Process, and Purpose}},
url = {http://dx.doi.org/10.1080/00031305.2016.1154108},
volume = {70},
year = {2016}
}

